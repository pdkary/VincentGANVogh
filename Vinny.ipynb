{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vinny.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/fXUnpLuJHw4PawmXi2T2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pdkary/VincentGANVogh/blob/main/Vinny.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Miy15PYkWHBr"
      },
      "source": [
        "!git clone https://github.com/pdkary/VincentGANVogh.git\n",
        "!pip install -r /content/VincentGANVogh/requirements.txt\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/content/VincentGANVogh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zkxFCq6SfsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd8dc47-3cb3-4d05-d773-4eae5079e3a2"
      },
      "source": [
        "from GanConfig import GanShapeConfig,GanBuildingConfig,GanTrainingConfig\n",
        "from GanTrainer import GanTrainer\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        " \n",
        "gan_shape_config = GanShapeConfig(\n",
        "    img_shape=(256,256,3),\n",
        "    latent_size=50,\n",
        "    style_size=100,\n",
        "    kernel_size=3,\n",
        "    style_layer_size=64,\n",
        "    style_layers=8,\n",
        "    gen_layer_shapes=[(1024,3),(512,3),(256,3),(128,2),(64,2),(16,2)],\n",
        "    disc_layer_shapes=[(64,2),(128,2),(256,3),(512,3),(512,3)],\n",
        "    disc_dense_sizes=[4096,4096],\n",
        "    minibatch_size=256,\n",
        ")\n",
        " \n",
        "gan_building_config = GanBuildingConfig(\n",
        "    relu_alpha=0.1,\n",
        "    dropout_rate=0.5,\n",
        "    batch_norm_momentum=0.8\n",
        ")\n",
        " \n",
        "gan_training_config = GanTrainingConfig(\n",
        "    learning_rate=1e-4,\n",
        "    disc_loss_function=\"binary_crossentropy\",\n",
        "    gen_loss_function=\"binary_crossentropy\",\n",
        "    gauss_factor=0.02,\n",
        "    batch_size=8,\n",
        "    preview_rows=3,\n",
        "    preview_cols=4,\n",
        "    data_path='/content/drive/MyDrive/Colab/VanGogh',\n",
        "    image_type=\".jpg\",\n",
        "    model_name='/GANVogh_generator_model_'\n",
        ")\n",
        "\n",
        "\n",
        "VGV = GanTrainer(gan_shape_config,gan_building_config,gan_training_config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model: \"generator_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "style_input (InputLayer)        [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "noise_image_input (InputLayer)  [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "latent_space_input (InputLayer) [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "generator_base (Functional)     (None, 256, 256, 3)  45087523    style_input[0][0]                \n",
            "                                                                 noise_image_input[0][0]          \n",
            "                                                                 latent_space_input[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "discriminator_base (Functional) (None, 1)            177256539   generator_base[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 222,344,062\n",
            "Trainable params: 45,087,523\n",
            "Non-trainable params: 177,256,539\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"discriminator_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "style_input (InputLayer)        [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "noise_image_input (InputLayer)  [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "latent_space_input (InputLayer) [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "image_input (InputLayer)        [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "generator_base (Functional)     (None, 256, 256, 3)  45087523    style_input[0][0]                \n",
            "                                                                 noise_image_input[0][0]          \n",
            "                                                                 latent_space_input[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "discriminator_base (Functional) (None, 1)            177256539   image_input[0][0]                \n",
            "                                                                 generator_base[1][0]             \n",
            "==================================================================================================\n",
            "Total params: 222,344,062\n",
            "Trainable params: 177,256,539\n",
            "Non-trainable params: 45,087,523\n",
            "__________________________________________________________________________________________________\n",
            "PREPARING DATASET\n",
            "LOADING FROM /content/drive/MyDrive/Colab/VanGogh/*.jpg\n",
            "LOADING 152 IMAGES\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoVhNjHlWvUV"
      },
      "source": [
        "#TRAINING\n",
        "ERAS = 100\n",
        "EPOCHS = 2500\n",
        "BATCHES_PER_EPOCH = 1\n",
        "PRINT_EVERY = 10\n",
        "\n",
        "VGV.train_n_eras(ERAS,EPOCHS,BATCHES_PER_EPOCH,PRINT_EVERY)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}